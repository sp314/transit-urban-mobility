library(tidyverse)
y <- 4
set.seed(30071999)
pred_1 <- rnorm(10000, mean = 0, sd = 1)
pred_2 <- rnorm(10000, mean = 10, sd = 3)
pred_3 <- rnorm(10000, mean = 10, sd = 6)
# Plot predictive models
dat <- data.frame(predictions = c(pred_1,pred_2,pred_3), model = rep(c("1","2","3"), each = 10000))
ggplot(dat, aes(x = predictions, fill = model)) +
geom_density(alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
# MSE for models 1, 2, & 3
(y - mean(pred_1))^2
(y - mean(pred_2))^2
(y - mean(pred_3))^2
# Weighted MSE for models 1, 2, & 3
(y - mean(pred_1))^2 / var(pred_1)
(y - mean(pred_2))^2 / var(pred_2)
(y - mean(pred_3))^2 / var(pred_3)
# Model that disregards bias in posterior estimator is vague
pred_4 <- rnorm(10000, mean = 100, sd = 100)
(y - mean(pred_4))^2 / var(pred_4)
mad(c(1,2,3), constant = 1)
# Comparing to median
abs(y - median(pred_1)) / mad(pred_1)
abs(y - median(pred_2)) / mad(pred_2)
abs(y - median(pred_3)) / mad(pred_3)
# Squared = similar to weighted MSE
(abs(y - median(pred_1)) / mad(pred_1))^2
(abs(y - median(pred_2)) / mad(pred_2))^2
(abs(y - median(pred_3)) / mad(pred_3))^2
mean(pred_1)
mean(pred_2)
mean(pred_3)
dic_fncn(pred_1)
dic_fncn <- function(pred){
pdic <- 2* (log(dnorm(y, mean = mean(pred))) - mean(log(dnorm(4, mean = pred))))
-2*log(dnorm(4, mean = mean(pred))) + 2*pdic
}
dic_fncn(pred_1)
dic_fncn(pred_2)
dic_fncn(pred_3)
dic_fncn(pred_1)
dic_fncn(pred_2)
dic_fncn(pred_3)
mean(pred)
mean(pred_2)
mean(pred_3)
dic_fncn(pred_2)
dic_fncn(pred_3)
dic_fncn <- function(pred){
pdic <- 2* (log(dnorm(y, mean = mean(pred))) - mean(log(dnorm(4, mean = pred))))
-2*log(dnorm(4, mean = mean(pred))) + 2*pdic
}
dic_fncn(pred_1)
dic_fncn(pred_2)
dic_fncn(pred_3)
log(dnorm(y, mean = mean(pred))
)
mean(log(dnorm(y, mean = mean(pred_1))))
dic_fncn <- function(pred){
pdic <- 2 * ( log(dnorm(y, mean = mean(pred))) - mean(log(dnorm(y, mean = mean(pred)))))
-2*log(dnorm(4, mean = mean(pred))) + 2*pdic
}
dic_fncn(pred_1)
dic_fncn(pred_2)
dic_fncn(pred_3)
dic_fncn(pred_1)
dic_fncn(pred_2)
dic_fncn(pred_3)
lpd <- log(dnorm(y, mean = theta, sd = 1))
# draw theta
theta <- rnorm(n = 1000, mean = 0, sd = 1)
lpd <- log(dnorm(y, mean = theta, sd = 1))
lpd
lpd <- dnorm(y, mean = theta, sd = 1, log = TRUE)
lpd
# log score of y on each model
dnorm(y, mean = 0, sd = 1, log = TRUE)
dnorm(y, mean = 10, sd = 3, log = TRUE)
dnorm(y, mean = 10, sd = 9, log = TRUE)
(abs(y - median(pred_3)) / mad(pred_3))^2
# Squared = similar to weighted MSE
(abs(y - median(pred_1)) / mad(pred_1))^2
# Squared = similar to weighted MSE
(y - median(pred_1) / mad(pred_1))^2
# Squared = similar to weighted MSE
(abs(y - median(pred_1)) / mad(pred_1))^2
# MSE for models 1, 2, & 3
(y - mean(pred_1))^2
(y - mean(pred_2))^2
(y - mean(pred_3))^2
abs(y - median(pred_1)
)
y - median(pred_1)
# Squared = similar to weighted MSE
(y - median(pred_1)) / mad(pred_1))^2
# Squared = similar to weighted MSE
((y - median(pred_1)) / mad(pred_1))^2
# Squared = similar to weighted MSE
(abs(y - median(pred_1)) / mad(pred_1))^2
# Squared = similar to weighted MSE
(abs(y - median(pred_1)) / mad(pred_1))^2
# Squared = similar to weighted MSE
(abs(y - median(pred_1)) / mad(pred_1))^2
(abs(y - median(pred_2)) / mad(pred_2))^2
(abs(y - median(pred_3)) / mad(pred_3))^2
(abs(y - median(pred_1)) / mad(pred_1))^2
(abs(y - median(pred_2)) / mad(pred_2))^2
(abs(y - median(pred_3)) / mad(pred_3))^2
((y - median(pred_1)) / mad(pred_1))^2
((y - median(pred_2)) / mad(pred_2))^2
((y - median(pred_3)) / mad(pred_3))^2
# Comparing to median
abs(y - median(pred_1))
# MSE for models 1, 2, & 3
(y - mean(pred_1))^2
(y - mean(pred_2))^2
(y - mean(pred_3))^2
# Comparing to median
abs(y - median(pred_1)) / mad(pred_1, constant = 1)
abs(y - median(pred_2)) / mad(pred_2, constant = 1)
abs(y - median(pred_3)) / mad(pred_3, constant = 1)
# Comparing to median
mad(pred_1, constant = 1)
# Comparing to median
median(pred_1)
mad(pred_1, constant = 1)
# Comparing to median
median(pred_1)
plot(rgamma(10000, shape = 2, rate = 4))
density(rgamma(10000, shape = 2, rate = 4))
plot(kde(rgamma(10000, shape = 2, rate = 4)))
plot(density(rgamma(10000, shape = 2, rate = 4)))
rgamma(10000, shape = 2, rate = 4) %>% mean()
rgamma(10000, shape = 2, rate = 4) %>% median()
rgamma(10000, shape = 2, rate = 4) %>% mode()
# Mode function
get_mode <- function(data) {
unique_values <- unique(data)
tab <- tabulate(match(data, unique_values))
unique_values[tab == max(tab)]
}
get_mode(pred_1)
get_mode(c(1,2,1,3,3,4,5))
match(c(1,2,1,3,3,4,5), c(1,2,3,4,5))
match(c(1,2,1,3,3,4,5,1), c(1,2,3,4,5))
# Mode function
get_mode <- function(data) {
unique_values <- unique(data)
tab <- tabulate(match(data, unique_values))
tab
}
get_mode(c(1,2,1,3,3,4,5,1))
get_mode(c(1,2,1,3,3,4,5,1))
match(c(1,2,1,3,3,4,5,1), unique(c(1,2,1,3,3,4,5,1)))
match(c(1,2,1,3,3,4,5,1), unique(c(1,2,1,3,3,4,5,1)))
unique(c(1,2,1,3,3,4,5,1))
match(c(1,2,1,3,3,4,5,1), c(1,2,3,4,5))
tabulate(match(c(1,2,1,3,3,4,5,1), c(1,2,3,4,5)))
tabulate(c(1,2,1,3,3,4,5,1))
tabulate(match(c(1,2,1,3,3,4,5,1,8), c(1,2,3,4,5)))
tabulate(match(c(1,2,1,3,3,4,5,1,8), c(1,2,3,4,5)))
match(c(1,2,1,3,3,4,5,1,8), c(1,2,3,4,5,8))
match(c(1,2,1,3,3,4,5,1,8,8), c(1,2,3,4,5,8))
match(c(20, 1,2,1,3,3,4,5,1,8,8), c(1,2,3,4,5,8,20))
# Mode function
get_mode <- function(data) {
unique_values <- unique(data)
tab <- tabulate(match(data, unique_values)) # Count unique values matches in index
unique_values[tab == max(tab)] # Go to max indices
}
get_mode(c(1,2,1,3,3,4,5))
# R scales the MAD.  Use constant = 1 to get raw
mad(c(1,2,3))
mad(c(1,2,3), constant = 1)
pred <- pred_1
dnorm(y, mean(pred), sd(pred), log = TRUE)
mean(dnorm(y, mean(pred), sd(pred), log = TRUE))
ggplot(dat, aes(x = predictions, fill = model)) +
geom_density(alpha = 0.5) +
geom_vline(xintercept = 4, color = "red") +
labs(x = "theta_n", y = "density")
pred_1 <- rnorm(10000, mean = theta_1, sd = 1)
set.seed(30071999)
theta_1 <- rnorm(10000, mean = 0, sd = 1)
theta_2 <- rnorm(10000, mean = 10, sd = 3)
theta_3 <- rnorm(10000, mean = 10, sd = 6)
pred_1 <- rnorm(10000, mean = theta_1, sd = 1)
ggplot(dat, aes(x = predictions, fill = model)) +
geom_density(alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
set.seed(30071999)
theta_1 <- rnorm(10000, mean = 0, sd = 1)
theta_2 <- rnorm(10000, mean = 10, sd = 3)
theta_3 <- rnorm(10000, mean = 10, sd = 6)
pred_1 <- rnorm(10000, mean = theta_1, sd = 1)
pred_2 <- rnorm(10000, mean = theta_2, sd = 1)
pred_3 <- rnorm(10000, mean = theta_3, sd = 1)
thetas <- data.frame(theta = c(theta_1,theta_2,theta_3), model = rep(c("1","2","3"), each = 10000)) %>%
mutate(y_pred = rnorm(n = 1, mean = theta, sd = 1))
distributions <- data.frame(theta = c(theta_1,theta_2,theta_3), model = rep(c("1","2","3"), each = 10000)) %>%
mutate(y_pred = rnorm(n = 1, mean = theta, sd = 1))
# Plot predictive distributions for y ~ N(\theta, 1)
distributions %>%
ggplot() +
geom_density(mapping = aes(x = theta, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
distributions %>%
ggplot() +
geom_density(mapping = aes(x = y_pred, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
distributions %>% View()
distributions <- data.frame(theta = c(theta_1,theta_2,theta_3), model = rep(c("1","2","3"), each = 10000)) %>%
rowwise() %>%
mutate(y_pred = rnorm(n = 1, mean = theta, sd = 1))
View(distributions)
# Plot predictive distributions for y ~ N(\theta, 1)
distributions %>%
ggplot() +
geom_density(mapping = aes(x = theta, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
distributions %>%
ggplot() +
geom_density(mapping = aes(x = y_pred, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
# Plot predictive distributions for y ~ N(\theta, 1)
distributions %>%
ggplot() +
geom_density(mapping = aes(x = theta, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
distributions %>%
ggplot() +
geom_density(mapping = aes(x = y_pred, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
pred_1 <- rnorm(10000, mean = theta_1, sd = 1)
pred_1
theta_1
theta_1[[1]]
pred_1[[1]]
rnorm(1, -0.457533, 1)
set.seed(30071999)
theta_1 <- rnorm(10000, mean = 0, sd = 1)
pred_1 <- rnorm(10000, mean = theta_1, sd = 1)
pred_1[1]
theta_1[1]
set.seed(30071999)
theta_1 <- rnorm(10000, mean = 0, sd = 1)
theta_2 <- rnorm(10000, mean = 10, sd = 3)
theta_3 <- rnorm(10000, mean = 10, sd = 6)
pred_1 <- rnorm(10000, mean = theta_1, sd = 1)
pred_2 <- rnorm(10000, mean = theta_2, sd = 1)
pred_3 <- rnorm(10000, mean = theta_3, sd = 1)
distributions <- data.frame(theta = c(theta_1,theta_2,theta_3), model = rep(c("1","2","3"), each = 10000),
y_pred = c(pred_1,pred_2,pred_3))
# Plot posterior distributions for \theta ~ N(?, ?)
distributions %>%
ggplot() +
geom_density(mapping = aes(x = theta, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
# Plot predictive distributions for y ~ N(\theta, 1)
distributions %>%
ggplot() +
geom_density(mapping = aes(x = y_pred, fill = model), alpha = 0.5) +
geom_vline(xintercept = 4, color = "red")
# MSE for models 1, 2, & 3
(y - mean(pred_1))^2
(y - mean(pred_2))^2
(y - mean(pred_3))^2
# Weighted MSE for models 1, 2, & 3
(y - mean(pred_1))^2 / var(pred_1)
(y - mean(pred_2))^2 / var(pred_2)
(y - mean(pred_3))^2 / var(pred_3)
# Model that disregards bias in posterior estimator is vague
pred_4 <- rnorm(10000, mean = 100, sd = 100)
(y - mean(pred_4))^2 / var(pred_4)
# Model that disregards bias in posterior estimator is vague
theta_4 <- rnorm(10000, mean = 100, sd = 100)
pred_4 <- rnorm(10000, mean = theta_4, sd = 1)
(y - mean(pred_4))^2 / var(pred_4)
# Weighted MSE for models 1, 2, & 3
(y - mean(pred_1))^2 / var(pred_1)
(y - mean(pred_2))^2 / var(pred_2)
(y - mean(pred_3))^2 / var(pred_3)
# Model that disregards bias in posterior estimator is vague
theta_4 <- rnorm(10000, mean = 100, sd = 100)
pred_4 <- rnorm(10000, mean = theta_4, sd = 1)
(y - mean(pred_4))^2 / var(pred_4)
# draw theta
theta <- rnorm(n = 1000, mean = 0, sd = 1)
lpd <- dnorm(y, mean = theta, sd = 1, log = TRUE)
mean(lpd) #elpd
# draw theta
theta <- rnorm(n = 1000, mean = 0, sd = 1)
lpd <- dnorm(y, mean = theta, sd = 1, log = TRUE)
mean(lpd) #elpd
# like plot on p20 of gelman
hist(log(dnorm(y, mean = theta, sd = 1)))
# log score of y on each model
dnorm(y, mean = 0, sd = 1, log = TRUE)
dnorm(y, mean = 10, sd = 3, log = TRUE)
dnorm(y, mean = 10, sd = 9, log = TRUE)
lpd
